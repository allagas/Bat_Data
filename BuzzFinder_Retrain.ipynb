{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BuzzFinder_Retrain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOF7Rkw6dPdliM3oAe7DJ1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allagas/Bat_Data/blob/master/BuzzFinder_Retrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiMst9nF61j-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db27e72e-5828-4c72-81d7-e313ff63271d"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9db4hNG7Bhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "672be056-d98b-4733-e77d-5dd62034acbe"
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "import datetime\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "\n",
        "CurrTime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "print('Training starting at ' + CurrTime)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.1.0\n",
            "Hub version: 0.7.0\n",
            "GPU is available\n",
            "Training starting at 20200224-160357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGQsy2FvAlwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cae2bfeb-4963-494c-a42e-ab9d29cda725"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkm9HEun8JII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d14aacc7-cdbb-4e7e-cac9-097ab05c13ab"
      },
      "source": [
        "module_selection = (\"inception_v3\", 299)\n",
        "handle_base, pixels = module_selection\n",
        "MODULE_HANDLE = \"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4 with input size (299, 299)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhlKbJOt8Qd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "N_TRAIN = int(1e4)\n",
        "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFvJdziK8ThA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "eec46c57-7268-4c5a-e79d-3a817056688d"
      },
      "source": [
        "! rm -r ./Bat_Data/\n",
        "! git clone https://github.com/allagas/Bat_Data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Bat_Data'...\n",
            "remote: Enumerating objects: 6596, done.\u001b[K\n",
            "remote: Counting objects: 100% (6596/6596), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6595/6595), done.\u001b[K\n",
            "remote: Total 6596 (delta 0), reused 6596 (delta 0), pack-reused 0\n",
            "Receiving objects: 100% (6596/6596), 1.20 GiB | 31.58 MiB/s, done.\n",
            "Checking out files: 100% (11916/11916), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5vAbWkO-34q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d76a3b8-9712-4f2b-d5e0-9e72f996080a"
      },
      "source": [
        "! ls Bat_Data/"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtZcBgPe9BU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = \"Bat_Data/Train/\"\n",
        "valid_dir = \"/Bat_Data/Valid/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68-UpVb19hsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       interpolation=\"bilinear\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5IsmPId9joc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "80439163-39a3-44fb-e66d-7cf90ca098e3"
      },
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir, shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = True\n",
        "if do_data_augmentation:\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=0,\n",
        "        horizontal_flip=False,\n",
        "        width_shift_range=0.2,\n",
        "        #height_shift_range=0.2,\n",
        "        **datagen_kwargs)\n",
        "else:\n",
        "    train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, shuffle=True, **dataflow_kwargs)\n",
        "\n",
        "do_fine_tuning = True\n",
        "\n",
        "print(\"Building model with\", MODULE_HANDLE)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 11916 images belonging to 2 classes.\n",
            "Building model with https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THZc98bY9uWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BuzzFinder = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          activation='softmax',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "BuzzFinder.build((None,)+IMAGE_SIZE+(3,))\n",
        "BuzzFinder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd2SNV_y9w4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start SGD w/ Learning Rate Decay\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "BuzzFinder.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(lr_schedule, nesterov=True, momentum=0.9),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.2),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "optimizer_type = \"_SGD\"\n",
        "\n",
        "# End SGD w/ LRD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpW1yvlD91_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = \"/media/philip/Bat_Data/BuzzFinder/perf_log/BuzzFinderModel\" + optimizer_type + CurrTime\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Sj6qPO93-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = BuzzFinder.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[tensorboard_callback]).history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA2mCf5c96zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model_path = \"/Bat_Data/BuzzFinder/BuzzFinderModel\" + optimizer_type + CurrTime\n",
        "tf.saved_model.save(BuzzFinder, saved_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x09cH83499Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "filenames = valid_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "cm_preds = BuzzFinder.predict(valid_generator, steps=nb_samples)\n",
        "\n",
        "# Match Prediction to Class Label\n",
        "preds_cls_idx = cm_preds.argmax(axis= 1)\n",
        "idx_to_cls = {v: k for k, v in valid_generator.class_indices.items()}\n",
        "preds_cls = np.vectorize(idx_to_cls.get)(preds_cls_idx)\n",
        "\n",
        "# Store Predictions in DataFrame\n",
        "df1 = pd.DataFrame({\"filenames\": filenames})\n",
        "df2 = pd.DataFrame({\"prediction\": preds_cls})\n",
        "df3 = pd.DataFrame({\"Buzz Prob\": cm_preds[:,0], \"Other Prob\": cm_preds[:,1]})\n",
        "predictions = pd.concat([df1, df2, df3], axis=1)\n",
        "\n",
        "print('Saving Predictions')\n",
        "\n",
        "# Save Predictions to CSV\n",
        "pred_save_dir = \"/media/philip/Bat_Data/predictions_\" + \"Valid_\" + CurrTime + \".csv\"\n",
        "predictions.to_csv(pred_save_dir)\n",
        "\n",
        "con_mat = tf.math.confusion_matrix(labels=valid_generator.classes, predictions=preds_cls_idx)\n",
        "print(con_mat)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}